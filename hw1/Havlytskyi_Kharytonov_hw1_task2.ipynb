{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fe44083c-b2d1-4370-a08c-53b19b8ec944",
      "metadata": {
        "id": "fe44083c-b2d1-4370-a08c-53b19b8ec944"
      },
      "outputs": [],
      "source": [
        "# We use torch and sklearn only on steps of fitting data\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from scipy.optimize import linprog\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2: Separating hyperplanes and the Perceptron Learning Algorithm (4 pts)\n",
        "### <div align=\"right\"> &copy; Yurii Yeliseev & Rostyslav Hryniv, 2022 </div>\n",
        "\n",
        "## Completed by:   \n",
        "*   Ivan Havlytskyi\n",
        "*   Oleksandr Kharytonov"
      ],
      "metadata": {
        "id": "EQznMLwjRzhi"
      },
      "id": "EQznMLwjRzhi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Description:\n",
        "#### The aim of this task is to discuss a simple binary classification method for linearly separated classes. The Perceptron Learning Algorithm finds a ***separating hyperplane*** in finitely many steps and is based on a clear geometric update method. We will derive the upper bound on the number of iterations in PLA and implement it for digit classification for the MNIST database.\n",
        "\n",
        "#### For this task of your homework you can get 3 points. Do not forget to save and rename the notebook before making any changes!"
      ],
      "metadata": {
        "id": "euyTTMP6nrDO"
      },
      "id": "euyTTMP6nrDO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Separating hyperplanes and classification (1.2 pts)"
      ],
      "metadata": {
        "id": "BPiRUcHnhqxX"
      },
      "id": "BPiRUcHnhqxX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. Binary classification.    \n",
        "A typical task of binary classification reads as follows. We are given the set of labelled (training) data $(\\mathbf{x}_k, y_k), k=1,2,\\dots, N$, where $\\mathbf{x}_k \\in \\mathbb{R}^d$ gives a data point and the label $y_k = \\pm1$ encodes the class (e.g. $y_k=1$ is the <font color='red'>''red''</font> class and $y_k=-1$ is the <font color='blue'>''blue''</font> one). The task is to find a classfier $f \\,:\\, \\mathbb{R}^d \\to \\pm1$ that would correctly recognize the classes, i.e. satisfy $y_k f(\\mathbf{x}_k) >0$ for all (or most) $k=1,2,\\dots,N$. This function can then be used to guess the class of new (unseen) data $\\mathbf{x}\\in\\mathbb{R}^n$.\n"
      ],
      "metadata": {
        "id": "F8uu18FS0NVJ"
      },
      "id": "F8uu18FS0NVJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1.2. Separating hyperplane  \n",
        "The simplest case is when the red and blue classes are *linearly separable*, i.e., when there is a hyperplane $H: \\mathbf{w} \\cdot \\mathbf{x} + w_0 = 0$ separating the red and blue datapoints. Then  $f(\\mathbf{x}) = \\mathbf{w}\\cdot \\mathbf{x} + w_0$ is an affine classifier, so that $f(\\mathbf{x}_k)>0$ for red points and $f(\\mathbf{x}_k)<0$ for blue ones. Augmenting $\\mathbf{x}$ to $\\widehat{\\mathbf{x}} := (1, \\mathbf{x})$ and $\\widehat{\\mathbf{w}} = (w_0,\\mathbf{w})$, we recognize that $f(\\mathbf{x})= \\widehat{\\mathbf{x}}\\cdot \\widehat{\\mathbf{w}}$. Therefore, the angles between $\\widehat{\\mathbf{x}}$ and $\\widehat{\\mathbf{w}}$ are acute for red datapoints and obtuse for the blue ones. The task is therefore to find the *normal vector* $\\widehat{\\mathbf{w}}$ with this properties."
      ],
      "metadata": {
        "id": "HqpK65XMSYul"
      },
      "id": "HqpK65XMSYul"
    },
    {
      "cell_type": "markdown",
      "id": "75612201-411f-48d9-8f36-629d8e8c5811",
      "metadata": {
        "tags": [],
        "id": "75612201-411f-48d9-8f36-629d8e8c5811"
      },
      "source": [
        "### 1.3. The idea behind the Perceptron learning algorithm (PLA)\n",
        "\n",
        "To simplify the notations, in what follows we will omit the \"hats\" above the $(d+1)$-dimensional vectors $\\widehat{\\mathbf{x}}$ and $\\widehat{\\mathbf{w}}$.\n",
        "\n",
        "PLA is an iterative algorithm that updates the direction vector ${\\mathbf{w}}$ towards a misclassified example, one at a time.\n",
        "\n",
        "Let's recall that correctly classified vectors $\\mathbf{x}_j$ must satisfy the inequality\n",
        "$$\n",
        "  y_j ({\\mathbf{w}}\\cdot {\\mathbf{x}}_j) > 0.\n",
        "$$\n",
        "If a red $\\mathbf{x}_j$ is misclassified, then the angle between ${\\mathbf{w}}$ and ${\\mathbf{x}}_j$ is obtuse. The idea is that we should decrease the angle between them by updating ${\\mathbf{w}}$ to ${\\mathbf{w}} + {\\mathbf{x}}_j$ (see Figure 1). Likewise, if a blue $\\mathbf{x}_j$ is misclassified, then the angle between ${\\mathbf{w}}$ and ${\\mathbf{x}}_j$ is acute, and we increase it be replacing ${\\mathbf{w}}$ with ${\\mathbf{w}} - {\\mathbf{x}}_j$. In both cases, the update is $${\\mathbf{w}} \\mapsto {\\mathbf{w}} + y_j {\\mathbf{x}}_j$$\n",
        "\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title></title>\n",
        "</head>\n",
        "<body>\n",
        "    <img src=\"https://drive.google.com/uc?export=view&id=12rduejeedS8NxrxXkSBJkkcDH3lB0k-R\">\n",
        "\n",
        "\n",
        "</body>\n",
        "</html>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4. **PLA**\n",
        "\n",
        "The above considerations suggest the following **PLA**:\n",
        "1.   Start with ${\\mathbf{w}}_0=\\mathbf{0}$ and classify the points\n",
        "2.   Take an arbitrary misclassified point\n",
        "3.   Update the ${\\mathbf{w}}$\n",
        "4.   Update the classification\n",
        "5.   Repeat 2-4 until there are misclassified points."
      ],
      "metadata": {
        "id": "xmDMvOJ9eNtd"
      },
      "id": "xmDMvOJ9eNtd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5. **PLA**: proof of convergence (1.2 pt)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "UBUdk2akoCMC"
      },
      "id": "UBUdk2akoCMC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.5.1 (0.4 pts)** Analyze the PLA update step  \n",
        "Prove that by updating ${\\mathbf{w}}$, we are decreasing or increasing (as required) the angle between ${\\mathbf{w}}$ and ${\\mathbf{x}}_j$.\n",
        "\n",
        "---\n",
        "\n",
        "#### Proof:\n",
        "\n",
        "Recall that the cosine of the angle $\\theta$ between two vectors $\\mathbf{w}$ and $\\mathbf{x}_j$ is given by:\n",
        "$$\\cos \\theta = \\frac{\\mathbf{w} \\cdot \\mathbf{x}_j}{\\|\\mathbf{w}\\| \\|\\mathbf{x}_j\\|}$$\n",
        "\n",
        "The angle decreases when $\\cos \\theta$ increases (for acute angles) and increases when $\\cos \\theta$ decreases (toward obtuse angles).\n",
        "\n",
        "**Case 1: Misclassified red point** ($y_j = +1$)\n",
        "\n",
        "- Since the point is misclassified: $y_j(\\mathbf{w} \\cdot \\mathbf{x}_j) = \\mathbf{w} \\cdot \\mathbf{x}_j < 0$\n",
        "- This means the angle between $\\mathbf{w}$ and $\\mathbf{x}_j$ is obtuse (> 90°)\n",
        "- After update: $\\mathbf{w}_{\\text{new}} = \\mathbf{w} + y_j\\mathbf{x}_j = \\mathbf{w} + \\mathbf{x}_j$\n",
        "\n",
        "Consider the dot product after update:\n",
        "$$\\mathbf{w}_{\\text{new}} \\cdot \\mathbf{x}_j = (\\mathbf{w} + \\mathbf{x}_j) \\cdot \\mathbf{x}_j = \\mathbf{w} \\cdot \\mathbf{x}_j + \\|\\mathbf{x}_j\\|^2$$\n",
        "\n",
        "Since $\\|\\mathbf{x}_j\\|^2 > 0$, we have:\n",
        "$$\\mathbf{w}_{\\text{new}} \\cdot \\mathbf{x}_j > \\mathbf{w} \\cdot \\mathbf{x}_j$$\n",
        "\n",
        "This means the dot product increased, making the angle **smaller** (less obtuse), which is what we want.\n",
        "\n",
        "**Case 2: Misclassified blue point** ($y_j = -1$)\n",
        "\n",
        "- Since the point is misclassified: $y_j(\\mathbf{w} \\cdot \\mathbf{x}_j) = -(\\mathbf{w} \\cdot \\mathbf{x}_j) < 0$\n",
        "- This means $\\mathbf{w} \\cdot \\mathbf{x}_j > 0$, so the angle is acute (< 90°)\n",
        "- After update: $\\mathbf{w}_{\\text{new}} = \\mathbf{w} + y_j\\mathbf{x}_j = \\mathbf{w} - \\mathbf{x}_j$\n",
        "\n",
        "Consider the dot product after update:\n",
        "$$\\mathbf{w}_{\\text{new}} \\cdot \\mathbf{x}_j = (\\mathbf{w} - \\mathbf{x}_j) \\cdot \\mathbf{x}_j = \\mathbf{w} \\cdot \\mathbf{x}_j - \\|\\mathbf{x}_j\\|^2$$\n",
        "\n",
        "Since $\\|\\mathbf{x}_j\\|^2 > 0$, we have:\n",
        "$$\\mathbf{w}_{\\text{new}} \\cdot \\mathbf{x}_j < \\mathbf{w} \\cdot \\mathbf{x}_j$$\n",
        "\n",
        "This means the dot product decreased (became less positive or even negative), making the angle **larger** (less acute or even obtuse), which is what we want.\n",
        "\n",
        "So, in both cases, the update moves $\\mathbf{w}$ in a direction that corrects the misclassification by adjusting the angle appropriately.\n",
        "\n",
        "Basically here we made a proof of the intuition in 1.3\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "oOn-vs9ye4B2"
      },
      "id": "oOn-vs9ye4B2"
    },
    {
      "cell_type": "markdown",
      "id": "e5680473-6119-4831-8990-ff6b3ac69e83",
      "metadata": {
        "id": "e5680473-6119-4831-8990-ff6b3ac69e83"
      },
      "source": [
        "#### **Assumptions and notations**\n",
        "\n",
        "***Assumption on linear separability*** There exists an ${\\mathbf{w}^{\\star}} \\in \\mathbb{R}^{d+1}$ of unit length and $\\gamma > 0$ such that $$y_k\\, {\\mathbf{x}}_k\\cdot {\\mathbf{w}}^{\\star} \\ge \\gamma, \\qquad k=1,2,\\dots, n.$$ The value $\\gamma$ determines the width of the *separating slab* free of any datapoints. The larger $\\gamma$, the wider the slab and the more robust the classifier is to noise in data.  \n",
        "\n",
        "We also denote by $R$ the maximum norm of $\\mathbf{x}_k$\n",
        "\n",
        "***Theorem on PLA convergence.*** The PLA makes at most $\\frac{R^2}{\\gamma^2}$ updates, after which it returns a separating hyperplane.\n",
        "\n",
        "***Proof.*** Should the algorthm terminate, then the resulting ${\\mathbf{w}}$ determines a separating hyperplane. Thus it suffices to show that the algorithm terminates after at most $\\frac{R^2}{\\gamma^2}$ updates. The approach is to get upper and lower bounds on the norm of the $k^{\\mathrm{th}}$ update ${\\mathbf{w}}_k$ of the weighting vector ${\\mathbf{w}}$, starting with ${\\mathbf{w}}_0 = \\mathbf{0}$.\n",
        "\n",
        "Assume that $k\\ge 1$ and ${\\mathbf{x}}_j$ is a misclasssified point on iteration $k$; then\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\mathbf{w}_{k+1} \\cdot {\\mathbf{w}}^{\\star} &=\\left({\\mathbf{w}}_k + y_j \\mathbf{x}_j\\right) \\cdot {\\mathbf{w}}^{\\star} \\\\\n",
        "&={\\mathbf{w}}_k \\cdot {\\mathbf{w}}^{\\star}+y_j\\left({\\mathbf{x}}_j \\cdot {\\mathbf{w}}^{\\star}\\right) \\\\\n",
        "&>{\\mathbf{w}}_k \\cdot {\\mathbf{w}}^{\\star} + \\gamma\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.5.2. (0.4 pts)** Explain by induction that ${\\mathbf{w}}_{k} \\cdot {\\mathbf{w}}^{\\star}> k \\gamma$.\n",
        "\n",
        "---\n",
        "\n",
        "#### Proof:\n",
        "\n",
        "We already have:\n",
        "$$\\mathbf{w}_{k+1} \\cdot \\mathbf{w}^* > \\mathbf{w}_k \\cdot \\mathbf{w}^* + \\gamma$$\n",
        "\n",
        "**Base case**, $k = 0$:\n",
        "- We start with $\\mathbf{w}_0 = \\mathbf{0}$\n",
        "- Therefore: $\\mathbf{w}_0 \\cdot \\mathbf{w}^* = 0 = 0 \\cdot \\gamma$\n",
        "\n",
        "**Inductive step:**\n",
        "- **Hypothesis:** Assume $\\mathbf{w}_k \\cdot \\mathbf{w}^* \\geq k\\gamma$ holds for some $k \\geq 0$\n",
        "- **To prove:** $\\mathbf{w}_{k+1} \\cdot \\mathbf{w}^* \\geq (k+1)\\gamma$\n",
        "\n",
        "From the given inequality before:\n",
        "$$\\mathbf{w}_{k+1} \\cdot \\mathbf{w}^* > \\mathbf{w}_k \\cdot \\mathbf{w}^* + \\gamma$$\n",
        "\n",
        "By the inductive hypothesis, we get:\n",
        "$$\\mathbf{w}_{k+1} \\cdot \\mathbf{w}^* > k\\gamma + \\gamma = (k+1)\\gamma$$\n",
        "\n",
        "Therefore, $\\mathbf{w}_{k+1} \\cdot \\mathbf{w}^* \\geq (k+1)\\gamma$\n",
        "\n",
        "Finally, by mathematical induction, $\\mathbf{w}_k \\cdot \\mathbf{w}^* \\geq k\\gamma$ for all $k \\geq 0$\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Quwk-bRAoONU"
      },
      "id": "Quwk-bRAoONU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a result, we see that\n",
        "$$\\|\\mathbf{w}_k\\| \\ge {\\mathbf{w}}_{k} \\cdot {\\mathbf{w}}^{\\star}> k \\gamma\\tag{1}$$\n",
        "\n",
        "To obtain the upper bound, we argue that\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\left\\|\\mathbf{w}_{k+1}\\right\\|^2 &=\\left\\|\\mathbf{w}_k+y_j \\mathbf{x}_j\\right\\|^2 \\\\\n",
        "&=\\left\\|\\mathbf{w}_k\\right\\|^2+\\left\\|y_j \\mathbf{x}_j\\right\\|^2+2\\left(\\mathbf{w}_k \\cdot \\mathbf{x}_j\\right) y_j \\\\\n",
        "&=\\left\\|\\mathbf{w}_k\\right\\|^2+\\left\\|\\mathbf{x}_j\\right\\|^2+2\\left(\\mathbf{w}_k \\cdot \\mathbf{x}_j\\right) y_j\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "3uu2Kmluod9X"
      },
      "id": "3uu2Kmluod9X"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.5.3. (0.4 pts)** Derive the lower bound\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\left\\|\\mathbf{w}_{k+1}\\right\\|^2\n",
        "&\\le\\left\\|\\mathbf{w}_k\\right\\|^2+\\left\\|\\mathbf{x}_j\\right\\|^2 \\\\\n",
        "&\\le\\left\\|\\mathbf{w}_k\\right\\|^2+R^2\n",
        "\\end{aligned}\n",
        "$$\n",
        "and use induction to conclude that\n",
        "$$\n",
        "\\left\\|\\mathbf{w}_{k}\\right\\|^2 \\le k\\, R^2 \\tag{2}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#### Proof:\n",
        "\n",
        "We need to derive an **upper bound** on $\\|\\mathbf{w}_k\\|^2$.\n",
        "\n",
        "When $\\mathbf{x}_j$ is misclassified at iteration $k$, we have $y_j(\\mathbf{w}_k \\cdot \\mathbf{x}_j) \\leq 0$.\n",
        "\n",
        "After the update $\\mathbf{w}_{k+1} = \\mathbf{w}_k + y_j\\mathbf{x}_j$:\n",
        "\n",
        "$$\\begin{aligned}\n",
        "\\|\\mathbf{w}_{k+1}\\|^2 &= \\|\\mathbf{w}_k + y_j\\mathbf{x}_j\\|^2 \\\\\n",
        "&= (\\mathbf{w}_k + y_j\\mathbf{x}_j) \\cdot (\\mathbf{w}_k + y_j\\mathbf{x}_j) \\\\\n",
        "&= \\|\\mathbf{w}_k\\|^2 + 2y_j(\\mathbf{w}_k \\cdot \\mathbf{x}_j) + y_j^2\\|\\mathbf{x}_j\\|^2 \\\\\n",
        "&= \\|\\mathbf{w}_k\\|^2 + 2y_j(\\mathbf{w}_k \\cdot \\mathbf{x}_j) + \\|\\mathbf{x}_j\\|^2 \\quad \\text{(since } y_j^2 = 1\\text{)}\n",
        "\\end{aligned}$$\n",
        "\n",
        "Since $\\mathbf{x}_j$ is misclassified: $y_j(\\mathbf{w}_k \\cdot \\mathbf{x}_j) \\leq 0$, therefore:\n",
        "$$\\|\\mathbf{w}_{k+1}\\|^2 \\leq \\|\\mathbf{w}_k\\|^2 + \\|\\mathbf{x}_j\\|^2$$\n",
        "\n",
        "By definition, $\\|\\mathbf{x}_j\\| \\leq R$ for all $j$, so:\n",
        "$$\\|\\mathbf{w}_{k+1}\\|^2 \\leq \\|\\mathbf{w}_k\\|^2 + R^2$$\n",
        "\n",
        "\n",
        "**Claim:** $\\|\\mathbf{w}_k\\|^2 \\leq kR^2$ for all $k \\geq 0$.\n",
        "\n",
        "Proof by induction:\n",
        "\n",
        "**Base case**, $k = 0$:\n",
        "$$\\|\\mathbf{w}_0\\|^2 = \\|\\mathbf{0}\\|^2 = 0 = 0 \\cdot R^2$$\n",
        "\n",
        "**Inductive step:**\n",
        "- **Hypothesis:** Assume $\\|\\mathbf{w}_k\\|^2 \\leq kR^2$ for some $k \\geq 0$\n",
        "- **To prove:** $\\|\\mathbf{w}_{k+1}\\|^2 \\leq (k+1)R^2$\n",
        "\n",
        "From the recurrence relation we derived earlier:\n",
        "$$\\|\\mathbf{w}_{k+1}\\|^2 \\leq \\|\\mathbf{w}_k\\|^2 + R^2$$\n",
        "\n",
        "Applying the inductive hypothesis:\n",
        "$$\\|\\mathbf{w}_{k+1}\\|^2 \\leq kR^2 + R^2 = (k+1)R^2$$\n",
        "\n",
        "Therefore, by mathematical induction, $\\|\\mathbf{w}_k\\|^2 \\leq kR^2$ for all $k \\geq 0$\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "BfKkTkx2YTrb"
      },
      "id": "BfKkTkx2YTrb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Together, (1) and (2) yield\n",
        "$$\n",
        "k^2 \\gamma^2<\\left\\|\\mathbf{w}_{k}\\right\\|^2 \\le k R^2,\n",
        "$$\n",
        "which implies the bound $k<\\frac{R^2}{\\gamma^2}$ and finishes the proof."
      ],
      "metadata": {
        "id": "Uk_bKxExoqXD"
      },
      "id": "Uk_bKxExoqXD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. PLA implementation on MNIST dataset (2.3 pts)"
      ],
      "metadata": {
        "id": "4vq40CCjb4tp"
      },
      "id": "4vq40CCjb4tp"
    },
    {
      "cell_type": "markdown",
      "id": "69405653-4bb7-4a5a-a6ab-6d06f81e2452",
      "metadata": {
        "id": "69405653-4bb7-4a5a-a6ab-6d06f81e2452"
      },
      "source": [
        "### 2.1. Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25024833-b7ae-48a4-b2d2-254aedb9e1ff",
      "metadata": {
        "id": "25024833-b7ae-48a4-b2d2-254aedb9e1ff"
      },
      "source": [
        "`train_data` is torch dataset object where images and targets lie inside `train_data.data` and `train_data.targets` respectively. To convert to numpy array you can use `.numpy()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "689dbfa9-1ed2-4baa-b0f0-8c094fa9a972",
      "metadata": {
        "id": "689dbfa9-1ed2-4baa-b0f0-8c094fa9a972",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85c78738-7089-4dbd-a8f8-54ea1673a34a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.1MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 488kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.51MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.85MB/s]\n"
          ]
        }
      ],
      "source": [
        "train_data = datasets.MNIST(root='data', train=True, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab0a6dd4-0ffe-4f59-bfad-b33824243772"
      },
      "source": [
        "### 2.2 Take 2 digits samples **(0.4 pts)**\n",
        "\n",
        "First of all you need to take only two digits samples from the dataset and convert the targets properly for the PLA. Choose the two digits based on the sum of your birthdays (e.g. 2 and 4 if it is 24; take 4 and 5 if it is 44)"
      ],
      "id": "ab0a6dd4-0ffe-4f59-bfad-b33824243772"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8cf9e98a-daff-4c94-9019-ace288e89bc9"
      },
      "outputs": [],
      "source": [
        "def filter_data(train_data, digit_1, digit_2):\n",
        "    \"\"\"\n",
        "    Take only digit_1 and digit_2 from the dataset and transform labels\n",
        "    Args:\n",
        "        train_data: torchvision.datasets.mnist.MNIST\n",
        "        digit_1: int (from 0 to 9)\n",
        "        digit_2: int (from 0 to 9)\n",
        "\n",
        "    Returns:\n",
        "        train_data: torchvision.datasets.mnist.MNIST or np.array\n",
        "    \"\"\"\n",
        "    # ========= YOUR CODE STARTS HERE ========= #\n",
        "    digits_cls = torch.tensor([digit_1, digit_2])\n",
        "    indices = torch.isin(train_data.targets, digits_cls)\n",
        "    train_data.data, train_data.targets = train_data.data[indices], train_data.targets[indices]\n",
        "    train_data.targets = torch.where(train_data.targets == digit_1, -1, 1)\n",
        "    # ========== YOUR CODE ENDS HERE ========== #\n",
        "    return train_data"
      ],
      "id": "8cf9e98a-daff-4c94-9019-ace288e89bc9"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dee2eaa6-498f-4174-875a-501548d56113"
      },
      "outputs": [],
      "source": [
        "train_data = filter_data(train_data, 4, 9) #Our sum is 23+26=49, so digit_1 = 4, digit_2 = 9"
      ],
      "id": "dee2eaa6-498f-4174-875a-501548d56113"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFga5wKx5qLn"
      },
      "source": [
        "### 2.3 Take a smaller subset and divide it into train and test sets **(0.4 pts)**\n",
        "\n",
        "\n",
        "Since the dataset is big, you need to use only part of it in this task (take\n",
        "~20-30% of the whole dataset for further processing).\n",
        "\n",
        "1. Properly subdivide dataset\n",
        "2. Calculate number samples in each class for test and train\n",
        "\n",
        "***Note***: you need to have same distributions inside train and test set"
      ],
      "id": "IFga5wKx5qLn"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "13cxSAQd5qLo"
      },
      "outputs": [],
      "source": [
        "def split_dataset(train_data):\n",
        "    \"\"\"\n",
        "    Split dataset into train and test parts.\n",
        "\n",
        "    !Hint: You can use train_test_split from sklearn for that\n",
        "\n",
        "    Args:\n",
        "        train_data: torchvision.datasets.mnist.MNIST or np.array\n",
        "\n",
        "    Returns:\n",
        "        X_train: Array of shape (N, 28, 28), images from the train set\n",
        "        y_train: Array of shape (N), labels from the train set\n",
        "\n",
        "        X_test: Array of shape (N, 28, 28), images from the test set\n",
        "        y_test: Array of shape (N), labels from the test set\n",
        "    \"\"\"\n",
        "    # ========= YOUR CODE STARTS HERE ========= #\n",
        "    X = train_data.data.numpy()\n",
        "    y = train_data.targets.numpy()\n",
        "\n",
        "    _, small_train_data, _, small_train_targets = train_test_split(\n",
        "        X, y,\n",
        "        test_size=0.25,\n",
        "        random_state=42,\n",
        "        stratify=y\n",
        "    )\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        small_train_data,\n",
        "        small_train_targets,\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=small_train_targets\n",
        "    )\n",
        "    # ========== YOUR CODE ENDS HERE ========== #\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "id": "13cxSAQd5qLo"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4pT-osLT5qLo"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = split_dataset(train_data)"
      ],
      "id": "4pT-osLT5qLo"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Unique values in y_train: {np.unique(y_train)}\")\n",
        "print(f\"Unique values in y_test: {np.unique(y_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8w3ABP6Li4f",
        "outputId": "e04a2f99-0f8c-4193-f1fd-1b0042d457c8"
      },
      "id": "k8w3ABP6Li4f",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in y_train: [-1  1]\n",
            "Unique values in y_test: [-1  1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of samples in train: {len(X_train)}\")\n",
        "print(f\"Classes number in train: {np.sum(y_train == 1)}, {np.sum(y_train == -1)}\")\n",
        "print(f\"Number of samples in test: {len(X_test)}\")\n",
        "print(f\"Classes number in test: {np.sum(y_test == 1)}, {np.sum(y_test == -1)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CZn6USNLTSX",
        "outputId": "532f8165-82b7-4846-b154-2b05f5eda7d7"
      },
      "id": "8CZn6USNLTSX",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in train: 2358\n",
            "Classes number in train: 1189, 1169\n",
            "Number of samples in test: 590\n",
            "Classes number in test: 298, 292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swE73GJ76GxU"
      },
      "source": [
        "### 2.4 Visualize samples for the train set"
      ],
      "id": "swE73GJ76GxU"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "0bc086ea-282c-476c-b69a-f39ac8009f25",
        "id": "6jc6fJqX6Gxe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig = plt.figure(figsize=(15, 5))\n",
        "for idx in np.arange(10):\n",
        "    ax = fig.add_subplot(2, 5, idx+1, xticks=[], yticks=[])\n",
        "    ax.imshow(np.squeeze(X_train[idx]), cmap='gray')\n",
        "    ax.set_title(str(y_train[idx].item()))"
      ],
      "id": "6jc6fJqX6Gxe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.5 Preprocess the samples and initialize $\\mathbf{w}$ **(0.5 pts)**"
      ],
      "metadata": {
        "id": "X2el3UpD6cYO"
      },
      "id": "X2el3UpD6cYO"
    },
    {
      "cell_type": "markdown",
      "id": "8531c05a-28a8-4309-98d2-b278e43be21f",
      "metadata": {
        "id": "8531c05a-28a8-4309-98d2-b278e43be21f"
      },
      "source": [
        "The original algorithm starts from zero parameter vector, but actually we can use just randomly initialized vector; it will make it faster to converge\n",
        "\n",
        "**Instructions**: Complete the missing lines of code and calculate the performance on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2a71993e-91fe-45af-bb58-040bbfd0cc40",
      "metadata": {
        "id": "2a71993e-91fe-45af-bb58-040bbfd0cc40"
      },
      "outputs": [],
      "source": [
        "def prep_data(X_train):\n",
        "    \"\"\"\n",
        "    Flatten, normalize and extra column for bias\n",
        "    Args:\n",
        "        X_train: np.array of shape (N, 28, 28)\n",
        "\n",
        "    Returns:\n",
        "        X: preprocessed data\n",
        "    \"\"\"\n",
        "    # ========= YOUR CODE STARTS HERE ========= #\n",
        "    # Flatten from (N, 28, 28) to (N, 784)\n",
        "    X = X_train.reshape(X_train.shape[0], -1)\n",
        "\n",
        "    # Normalize to [0, 1] range\n",
        "    X = X / 255.0\n",
        "\n",
        "    # Add bias column (ones) at the beginning\n",
        "    X = np.c_[np.ones(X.shape[0]), X]\n",
        "    # ========== YOUR CODE ENDS HERE ========== #\n",
        "    return X\n",
        "\n",
        "def initialize_weight_vector(size):\n",
        "    \"\"\"\n",
        "    Create random parameter vector\n",
        "    Args:\n",
        "        size: Number of elements\n",
        "\n",
        "    Returns:\n",
        "        W: np.array of shape (size)\n",
        "    \"\"\"\n",
        "    # ========= YOUR CODE STARTS HERE ========= #\n",
        "    return np.random.randn(size) * 0.01\n",
        "    # ========== YOUR CODE ENDS HERE ========== #\n",
        "\n",
        "def misclassified(X, y, W):\n",
        "    \"\"\"\n",
        "    Calculate indices of missclasified points\n",
        "    Args:\n",
        "        X: np.array, training images\n",
        "        y: np.array, training labels\n",
        "        w: np.array, parameter vector\n",
        "\n",
        "    Returns:\n",
        "        M: np.array of shape (m) - indices of missclasified points, where m is a number of missclasified points\n",
        "    \"\"\"\n",
        "    # ========= YOUR CODE STARTS HERE ========= #\n",
        "    predictions = np.dot(X, W)\n",
        "\n",
        "    misclass_mask = y * predictions <= 0\n",
        "\n",
        "    return np.where(misclass_mask)[0]\n",
        "    # ========== YOUR CODE ENDS HERE ========== #\n",
        "\n",
        "\n",
        "X_train_flat_aug = prep_data(X_train)\n",
        "W = initialize_weight_vector(X_train_flat_aug.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c942c8e-1a2b-47f0-af9a-8ac09905c8d4",
      "metadata": {
        "id": "4c942c8e-1a2b-47f0-af9a-8ac09905c8d4"
      },
      "source": [
        "### 2.6 Training loop **(0.6 pts)**\n",
        "Here you need to complete the training loop of the PLA algorithm. Observe that recalculation the misclassified set (Step 3 of the PLA algorithm) is the most costly (as we need to iterate through the whole train set). To speed up the algorithm convergence, we will do the following:\n",
        "-  determine the set $S$ of misclassified datapoints\n",
        "-  for every $\\mathbf{w}\\in S$ that is still misclassified, update the vector $\\mathbf{w}$\n",
        "-  only after that recalculate the set $S$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    \"\"\"\n",
        "    Returns:\n",
        "        W: the final vector of weights for the separating hyperplane\n",
        "    \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xvAjIf13OAHH",
        "outputId": "aeece842-5fd9-4f73-af24-e59266eb4b38"
      },
      "id": "xvAjIf13OAHH",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nReturns:\\n    W: the final vector of weights for the separating hyperplane\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ac792433-7ba8-483a-929f-c10fe0353b86",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac792433-7ba8-483a-929f-c10fe0353b86",
        "outputId": "d3e8f2b1-a129-4100-b752-63f6327e96a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found separating hyperplane on step 2104!\n"
          ]
        }
      ],
      "source": [
        "for i in range(10000):\n",
        "    misclass = misclassified(X_train_flat_aug, y_train, W)\n",
        "    if len(misclass) == 0:\n",
        "        print(f\"Found separating hyperplane on step {i}!\")\n",
        "        break\n",
        "\n",
        "    # ========= YOUR CODE STARTS HERE ========= #\n",
        "    for idx in misclass:\n",
        "        if y_train[idx] * np.dot(X_train_flat_aug[idx], W) <= 0:\n",
        "            W = W + y_train[idx] * X_train_flat_aug[idx]\n",
        "    # ========== YOUR CODE ENDS HERE ========== #"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Increased number of iterations to test convergence. These digits are similar-looking (both have curves) -> This means small γ (narrow margin) ->  large $$ \\frac{R^2}{\\gamma^2} $$​ -> many iterations needed"
      ],
      "metadata": {
        "id": "_e3kR84ntpAf"
      },
      "id": "_e3kR84ntpAf"
    },
    {
      "cell_type": "markdown",
      "id": "151d7f57-bdec-4b35-9bca-22778c7778e9",
      "metadata": {
        "id": "151d7f57-bdec-4b35-9bca-22778c7778e9"
      },
      "source": [
        "### 2.7 Evaluate performance of the linear classifier on the test set **(0.4 pts)**\n",
        "\n",
        "Check your classifier on the test set. Think of possible metrics that characterize performance and comment on how good the classifier is"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ea11a6c7-e4a3-439d-a836-19455f3d643a",
      "metadata": {
        "id": "ea11a6c7-e4a3-439d-a836-19455f3d643a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        },
        "outputId": "ae6c69ad-7a8d-4e69-e7b5-a89efbd0657e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "TEST SET PERFORMANCE EVALUATION\n",
            "============================================================\n",
            "\n",
            "Total test samples: 590\n",
            "Class -1: 292 samples\n",
            "Class +1: 298 samples\n",
            "\n",
            "------------------------------------------------------------\n",
            "CLASSIFICATION METRICS:\n",
            "------------------------------------------------------------\n",
            "Accuracy:       94.58%\n",
            "Error Rate:     5.42%\n",
            "Misclassified:  32 out of 590\n",
            "Precision:      0.9404\n",
            "Recall:         0.9530\n",
            "F1-Score:       0.9467\n",
            "\n",
            "------------------------------------------------------------\n",
            "CONFUSION MATRIX:\n",
            "------------------------------------------------------------\n",
            "                 Predicted -1    Predicted +1\n",
            "Actual -1           274              18\n",
            "Actual +1            14             284\n",
            "\n",
            "------------------------------------------------------------\n",
            "DETAILED BREAKDOWN:\n",
            "------------------------------------------------------------\n",
            "True Positives:  284 (correctly classified as +1)\n",
            "True Negatives:  274 (correctly classified as -1)\n",
            "False Positives: 18 (incorrectly classified as -1)\n",
            "False Negatives: 14 (incorrectly classified as +1)\n",
            "\n",
            "------------------------------------------------------------\n",
            "MISCLASSIFIED EXAMPLES: 32 total\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ========= YOUR CODE STARTS HERE ========= #\n",
        "\n",
        "X_test_flat_aug = prep_data(X_test)\n",
        "\n",
        "test_predictions = np.dot(X_test_flat_aug, W)\n",
        "test_pred_labels = np.sign(test_predictions)\n",
        "\n",
        "test_pred_labels[test_pred_labels == 0] = 1\n",
        "\n",
        "misclass_test_indices = misclassified(X_test_flat_aug, y_test, W)\n",
        "\n",
        "accuracy = 1 - (len(misclass_test_indices) / len(y_test))\n",
        "error_rate = len(misclass_test_indices) / len(y_test)\n",
        "\n",
        "true_positives = np.sum((test_pred_labels == 1) & (y_test == 1))\n",
        "true_negatives = np.sum((test_pred_labels == -1) & (y_test == -1))\n",
        "false_positives = np.sum((test_pred_labels == 1) & (y_test == -1))\n",
        "false_negatives = np.sum((test_pred_labels == -1) & (y_test == 1))\n",
        "\n",
        "precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
        "recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
        "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"TEST SET PERFORMANCE EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nTotal test samples: {len(y_test)}\")\n",
        "print(f\"Class -1: {np.sum(y_test == -1)} samples\")\n",
        "print(f\"Class +1: {np.sum(y_test == 1)} samples\")\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"CLASSIFICATION METRICS:\")\n",
        "print(\"-\"*60)\n",
        "print(f\"Accuracy:       {accuracy * 100:.2f}%\")\n",
        "print(f\"Error Rate:     {error_rate * 100:.2f}%\")\n",
        "print(f\"Misclassified:  {len(misclass_test_indices)} out of {len(y_test)}\")\n",
        "print(f\"Precision:      {precision:.4f}\")\n",
        "print(f\"Recall:         {recall:.4f}\")\n",
        "print(f\"F1-Score:       {f1_score:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"CONFUSION MATRIX:\")\n",
        "print(\"-\"*60)\n",
        "print(f\"                 Predicted -1    Predicted +1\")\n",
        "print(f\"Actual -1        {true_negatives:6d}          {false_positives:6d}\")\n",
        "print(f\"Actual +1        {false_negatives:6d}          {true_positives:6d}\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"DETAILED BREAKDOWN:\")\n",
        "print(\"-\"*60)\n",
        "print(f\"True Positives:  {true_positives} (correctly classified as +1)\")\n",
        "print(f\"True Negatives:  {true_negatives} (correctly classified as -1)\")\n",
        "print(f\"False Positives: {false_positives} (incorrectly classified as -1)\")\n",
        "print(f\"False Negatives: {false_negatives} (incorrectly classified as +1)\")\n",
        "\n",
        "if len(misclass_test_indices) > 0:\n",
        "    print(f\"\\n\" + \"-\"*60)\n",
        "    print(f\"MISCLASSIFIED EXAMPLES: {len(misclass_test_indices)} total\")\n",
        "    print(\"-\"*60)\n",
        "\n",
        "    fig = plt.figure(figsize=(15, 3))\n",
        "    num_show = min(10, len(misclass_test_indices))\n",
        "\n",
        "    for i in range(num_show):\n",
        "        idx = misclass_test_indices[i]\n",
        "        ax = fig.add_subplot(1, num_show, i+1, xticks=[], yticks=[])\n",
        "        ax.imshow(X_test[idx], cmap='gray')\n",
        "        ax.set_title(f\"True: {y_test[idx]}\\nPred: {int(test_pred_labels[idx])}\",\n",
        "                    color='red', fontsize=10)\n",
        "        ax.set_xlabel(f\"Score: {test_predictions[idx]:.2f}\", fontsize=8)\n",
        "\n",
        "    plt.suptitle(\"Examples of Misclassified Images\", fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ========== YOUR CODE ENDS HERE ========== #"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Conclusions **(0.5 pts)**\n",
        "\n",
        "Summarize in a few sentences what you have learned and achieved by completing the tasks of this assignment\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "This assignment provided both theoretical and practical understanding of the Perceptron Learning Algorithm. We proved PLA's convergence guarantee and implemented it for binary MNIST classification, achieving 92% accuracy on digits 4 vs 9.\n",
        "\n",
        "Key learnings: the critical role of -1/+1 label encoding for proper geometric updates, efficient batch processing of misclassified points, and the connection between mathematical theory and practical implementation. The successful convergence demonstrated that the chosen digit pair is linearly separable."
      ],
      "metadata": {
        "id": "xq-iaKD2jgYU"
      },
      "id": "xq-iaKD2jgYU"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UBUdk2akoCMC",
        "69405653-4bb7-4a5a-a6ab-6d06f81e2452",
        "ab0a6dd4-0ffe-4f59-bfad-b33824243772",
        "IFga5wKx5qLn",
        "swE73GJ76GxU",
        "X2el3UpD6cYO",
        "4c942c8e-1a2b-47f0-af9a-8ac09905c8d4",
        "151d7f57-bdec-4b35-9bca-22778c7778e9"
      ],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}